{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeightWatcher GPT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T23:51:16.544327Z",
     "start_time": "2019-03-05T23:51:16.531457Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-01-01T21:19:25.195978-08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.6\n",
      "IPython version      : 7.11.1\n",
      "\n",
      "Compiler    : Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "OS          : Darwin\n",
      "Release     : 17.7.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T22:51:12.554859Z",
     "start_time": "2018-10-01T22:51:12.518859Z"
    }
   },
   "source": [
    "### Import WeightWatcher\n",
    "\n",
    "set custom Logging at WARN Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:16:41.769719Z",
     "start_time": "2019-03-06T00:16:38.803181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "INFO:pytorch_transformers.modeling_bert:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_transformers.modeling_xlnet:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch  1.0.1\n",
      "WeightWatcher  0.2.2\n",
      "PyTorch Transformers 1.2.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "import torch\n",
    "import weightwatcher as ww\n",
    "import pytorch_transformers  as ppb\n",
    "\n",
    "print(\"Torch \",torch.__version__)\n",
    "print(\"WeightWatcher \",ww.__version__)\n",
    "print(\"PyTorch Transformers\",ppb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all models now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = ppb.BertModel.from_pretrained(init_checkpoint_pt)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_name = 'GPT'\n",
    "all_names = [ 'densenet121', 'densenet169', 'densenet201', 'densenet161']\n",
    "colors = ['blue', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:16:43.249725Z",
     "start_time": "2019-03-06T00:16:43.240611Z"
    }
   },
   "outputs": [],
   "source": [
    "all_models = []\n",
    "all_models.append(models.densenet121(pretrained=True))\n",
    "all_models.append(models.densenet161(pretrained=True))\n",
    "all_models.append(models.densenet169(pretrained=True))\n",
    "all_models.append(models.densenet201(pretrained=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reported accuracies from pytorch website\n",
    "\n",
    "https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "\n",
    "<pre>\n",
    "<table class=\"docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 55%\" />\n",
    "<col style=\"width: 22%\" />\n",
    "<col style=\"width: 22%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Network</p></th>\n",
    "<th class=\"head\"><p>Top-1 error</p></th>\n",
    "<th class=\"head\"><p>Top-5 error</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "\n",
    "<tr class=\"row-even\"><td><p>Densenet-121</p></td>\n",
    "<td><p>25.35</p></td>\n",
    "<td><p>7.83</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>Densenet-169</p></td>\n",
    "<td><p>24.00</p></td>\n",
    "<td><p>7.00</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>Densenet-201</p></td>\n",
    "<td><p>22.80</p></td>\n",
    "<td><p>6.43</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>Densenet-161</p></td>\n",
    "<td><p>22.35</p></td>\n",
    "<td><p>6.20</p></td>\n",
    "</tr>\n",
    "\n",
    "</tbody>\n",
    "</table>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_errors= {\n",
    "    \n",
    "    \"densenet121\": 25.35,\n",
    "    \"densenet169\": 24.00,\n",
    "    \"densenet201\": 22.80,\n",
    "    \"densenet161\": 22.35 \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_errors= {\n",
    "    \n",
    "    \"densenet121\": 7.83,\n",
    "    \"densenet169\": 7.00,\n",
    "    \"densenet201\": 6.43,\n",
    "    \"densenet161\": 6.20 \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run WeightWatcher, collect summary and details (as dataframes) for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_details = []\n",
    "all_summaries = []\n",
    "for im, name in enumerate(all_names):\n",
    "    watcher = ww.WeightWatcher(model=all_models[im], logger=logger)\n",
    "    results = watcher.analyze(alphas=True, softranks=True, spectralnorms=True, mp_fit=True)\n",
    "\n",
    "    summary =  watcher.get_summary()\n",
    "    all_summaries.append(summary)\n",
    "    details  = watcher.get_details(results=results)\n",
    "    details.drop(columns=['slice', 'slice_count'], inplace=True)\n",
    "    details.dropna(inplace=True)\n",
    "    details['NxM'] = pd.to_numeric(details.N * details.M)\n",
    "\n",
    "    all_details.append(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "def plot_test_accuracy(metric, xlabel, title):\n",
    "    \"\"\"Create plot of Metric vs Reported Test Accuracy, and run Linear Regression\"\"\"\n",
    "    num = len(all_names)\n",
    "    xs, ys = np.empty(num), np.empty(num)\n",
    "    for im, modelname in enumerate(all_names):    \n",
    "\n",
    "        summary = all_summaries[im]\n",
    "        x = summary[metric]\n",
    "        xs[im] = x\n",
    "\n",
    "        error = top1_errors[modelname]\n",
    "        y = 100.0-error\n",
    "        ys[im] = y\n",
    "\n",
    "        label = modelname\n",
    "        plt.scatter(x, y, label=label)\n",
    "\n",
    "\n",
    "    xs = xs.reshape(-1,1)\n",
    "    ys = ys.reshape(-1,1)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(xs, ys)\n",
    "    y_pred = regr.predict(xs)\n",
    "    plt.plot(xs, y_pred, color='red', linewidth=1)\n",
    "\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(ys, y_pred))\n",
    "    r2 = metrics.r2_score(ys, y_pred)\n",
    "    title2 = \"RMSE: {0:.2}   R2: {0:.2}\".format(rmse, r2)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(r\"Test Accuracy vs \"+title+\"\\n\"+title2)\n",
    "    plt.ylabel(r\"Test Accuracy\")\n",
    "    plt.xlabel(xlabel);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_histogram(metric, xlabel, title, log=False, valid_ids = []):\n",
    "    transparency = 1.0\n",
    "    \n",
    "    if len(valid_ids) == 0:\n",
    "        valid_ids = range(len(all_details)-1)\n",
    "        \n",
    "    for im, details in enumerate(all_details):\n",
    "        if im in valid_ids:\n",
    "            vals = details[metric].to_numpy()\n",
    "            if log:\n",
    "                vals = np.log10(np.array(vals+0.000001, dtype=np.float))\n",
    "\n",
    "            plt.hist(vals, bins=100, label=all_names[im], alpha=transparency, color=colors[im], density=True)\n",
    "            transparency -= 0.15\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_depth(metric, ylabel, title, log=False, valid_ids = []):\n",
    "    transparency = 1.0\n",
    "    \n",
    "    if len(valid_ids) == 0:\n",
    "        valid_ids = range(len(all_details)-1)\n",
    "        \n",
    "    for im, details in enumerate(all_details):\n",
    "        if im in valid_ids:\n",
    "            \n",
    "            details = all_details[im]\n",
    "            name = all_names[im]\n",
    "            x = details.index.to_numpy()\n",
    "            y = details[metric].to_numpy()\n",
    "            if log:\n",
    "                y = np.log10(np.array(y+0.000001, dtype=np.float))\n",
    "\n",
    "            plt.scatter(x,y, label=name, color=colors[im])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Layer id\")\n",
    "    plt.ylabel(xlabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics vs Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = \"lognorm\"\n",
    "xlabel = r\"$\\langle\\log\\Vert W\\Vert\\rangle_{F}$\"\n",
    "title = \"Average Log Frobenius Norm \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "\n",
    "metric = \"alpha\"\n",
    "xlabel = r\"$\\alpha$\"\n",
    "title = \"Average  Alpha  \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"$\\hat{\\alpha}$\"\n",
    "title = \"Average Weighted Alpha  \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"spectralnorm\"\n",
    "xlabel = r\"$\\langle\\Vert\\mathbf{W}\\Vert_{2}\\rangle$\"\n",
    "title = \"Average Log Spectral Norm  \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"softranklog\"\n",
    "xlabel = r\"$\\langle\\mathcal{R}_{s}\\rangle$\"\n",
    "title = \"Average Log Stable Rank \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"logpnorm\"\n",
    "xlabel = r\"$\\langle\\Vert\\mathbf{W}\\Vert^{\\alpha}\\rangle$\"\n",
    "title = \"Average Log pNorm \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of metrics for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n_last_ids = [0, len(all_details)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = \"lognorm\"\n",
    "xlabel = r\"Log Frobenius Norm $\\langle\\log\\Vert W\\Vert\\rangle_{F}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha\"\n",
    "xlabel = r\"Alpha $\\alpha$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"Weighted Alpha $\\hat{\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "\n",
    "metric = \"softranklog\"\n",
    "xlabel = r\"Log Stable Rank $\\mathcal{R}_{s}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"spectralnorm\"\n",
    "xlabel = r\"Log Spectral Norm $\\Vert\\mathbf{W}\\Vert_{2}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title, log=True)\n",
    "plot_metrics_histogram(metric, xlabel, title, log=True, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"softrank_mp\"\n",
    "xlabel = r\"Log MP Soft Rank $\\mathcal{R}_{mp}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "metric = \"logpnorm\"\n",
    "xlabel = r\"Log p-Norm $\\Vert\\mathbf{W}\\Vert^{\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics as a function of depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = \"lognorm\"\n",
    "xlabel = r\"Log Frobenius Norm $\\langle\\log\\Vert W\\Vert\\rangle_{F}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha\"\n",
    "xlabel = r\"Alpha $\\alpha$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"Weighted Alpha $\\hat{\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "\n",
    "metric = \"softranklog\"\n",
    "xlabel = r\"Log Stable Rank $\\mathcal{R}_{s}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"spectralnorm\"\n",
    "xlabel = r\"Log Spectral Norm $\\Vert\\mathbf{W}\\Vert_{2}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title, log=True)\n",
    "plot_metrics_depth(metric, xlabel, title, log=True, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"softrank_mp\"\n",
    "xlabel = r\"Log MP Soft Rank $\\mathcal{R}_{mp}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "metric = \"logpnorm\"\n",
    "xlabel = r\"Log p-Norm $\\Vert\\mathbf{W}\\Vert^{\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
