\section{Comparison of 3 Computer Vision Models}
\label{sxn:cv}


\michael{We set up the methdology we will use later, and give examples on the CV models
and explain how to interpret things a bit. We study pretrained CV models.
We look at correlation with the reportest test accuarcies.
 We will run linear regressions. We will compute the RMSE.  
We study alpha and the 4 norms.  we could add softrank with some work.

We introduce the notion of Correlation Flow and 
tell a nice story about residual connections
with VGG RseNet and DenseNet}

\paragraph{Empirical Metrics vs Test Accuracies for CV models}

\begin{figure}[t]
    \centering
    \subfigure[ Frobenius Norm ]{
        \includegraphics[width=5cm]{img/VGG_lognorm_accs.png}
        \label{fig:vgg-fnorm}
    }
    \qquad
    \subfigure[ Spectral Norm ]{
        \includegraphics[width=4.9cm]{img/VGG_spectralnorm_accs.png}
        \label{fig:vgg-snorm}
    }
    \qquad
    \subfigure[ Weighted Alpha ]{
        \includegraphics[width=4.9cm]{img/VGG_alpha_weighted_accs.png}
        \label{fig:vgg-walpha}
    }
    \qquad
    \subfigure[ Alpha-Norm ]{
        \includegraphics[width=4.9cm]{img/VGG_logpnorm_accs.png}
        \label{fig:vgg-pnorm}
    }
    \caption{Comparison of norm metrics vs reported test accuracy for pretrained VGG models, trained on ImageNet, available in pyTorch.  Plots will be updated and replace }
    

    \label{fig:vgg-metrics}
\end{figure}


VGG works remarkably well

ResNet is also correlated, but the RMSE is much larger, and 2/5 of the models are almost outliers
But note that the PyTorch distribution only has a few models.
The ResNet results look better when considering all ResNet models, trained on ImageNet1K.

ADD PLOTS FOR


\begin{figure}[t]
    \centering

    \subfigure[ ResNet ]{
        \includegraphics[width=4.2cm]{img/ResNet_logpnorm_accs.png}
        \label{fig:resnet-accuracy}
    }
    \qquad
    \subfigure[ ResNet-1K ]{
        \includegraphics[width=4.5cm]{img/ResNet-1K_logpnorm_accs.png}
        \label{fig:resnet1k-accuracy}
    }
    \qquad
    \subfigure[ DenseNet ]{
        \includegraphics[width=4.4cm]{img/DenseNet_logpnorm_accs.png}
        \label{fig:densenet-accuracy}
    }
    \caption{$\alpha$-Norm vs reported Top1 Error for  ResNet, ResNet-1K, and DenseNet models}
    \label{fig:cv2-accuracy}
\end{figure}


TODO:  add table of metrics for these 3 models, show that alpha-Norm is best again!

\begin{table}[t]
\small
\begin{center}
\begin{tabular}{|p{1in}|c|c|c|c|c|}
\hline
   &    & Frobenius Norm & Spectral Norm & Weighted Alpha & Alpha-Norm \\
 Series & \#Models   & $\Vert\mathbf{W}\Vert_{F}$ & $\Vert\mathbf{W}\Vert_{\infty}$ & $\hat{\alpha}=\alpha\log\lambda_{max}$ & $\Vert\mathbf{X}\Vert^{\alpha}_{\alpha}$ \\
\hline
 VGG & 6 & 0.56 & 0.53 & 0.48 & 0.42  \\
 ResNet & 5 & 0.9 & 1.4 & 0.61 & 0.66  \\
 ResNet-1K & 19 & 2.4 & 3.6 & 1.8 & 1.9  \\
 DenseNet & 4 & 0.3 & 0.26 & 0.16 & 0.21 \\
\hline
\end{tabular}
\end{center}
\caption{RMSE for Linear Fits of Metric to Reported Top1 Test Error for all pre-trained models in the architecture series.  All models trained on ImageNet except ResNet-1K, which was trained on ImageNet-1K. }
\label{table:models}
\end{table}

DISCUSS TABLE



\paragraph{Correlation Flow in CV Models}

Explain WHAT IS \emph{Correlation Flow}

Compare VGG, ResNet, and DenseNet in the context of how many connections that have

\begin{figure}[t]
    \centering

    \subfigure[ VGG ]{
        \includegraphics[width=4.5cm]{img/VGG_fnl_alpha_depth.png} 
                \label{fig:vgg-alpha-layers}
    }
    \qquad
    \subfigure[ ResNet ]{
        \includegraphics[width=4.5cm]{img/ResNet_fnl_alpha_depth.png} 
        \label{fig:resnet-alpha-layer}
    }
    \qquad
    \subfigure[ DenseNet ]{
        \includegraphics[width=4.5cm]{img/DenseNet_fnl_alpha_depth.png} 
        \label{fig:densenet-alpha-layer}
    }
    \caption{Power law exponent $\alpha$ vs layer for VGG, ResNet, and DenseNet models}
    \label{fig:vgg-alpha-layers}
\end{figure}


