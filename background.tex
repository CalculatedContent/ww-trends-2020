\section{Background and Related Work}
\label{sxn:background}

Most theory for DNNs is applied to small toy models and assumes access to data.
There is very little work asking how to predict, in a theoretically-principled manner, the quality of large-scale state-of-the-art NNs, and how to do so without access to training data or testing data or details of the training protocol, etc.
Our work is, however, loosely related to several other lines of work.

\paragraph{Statistical mechanical theory of NNs.}

Statistical mechanical ideas have long had influence on NN theory and practice~\cite{EB01_BOOK, MM17_TR, BKPx20}; and 
our best-performing metrics (i.e., those using fitted PL exponents and HT-SR Theory) are based on statistical mechanics ideas~\cite{MM17_TR, MM18_TR, MM19_HTSR_ICML, MM19_KDD, MM20_SDM}.
\michael{Where first define HT-SR.}
However, that the way in which we \emph{use} statistical mechanics theory is quite different than the way it is more commonly formulated.
Several very good overviews of the more common approach are available~\cite{EB01_BOOK, BKPx20}.
We will \emph{use} statistical mechanics theory more as it is used in quantitative finance.
Thus, much more relevant for our metholodogical approach is older work of Bouchaud, Potters, Sornette, and coworkers~\cite{BouchaudPotters03, SornetteBook, BP11, bun2017} on the statisical mechanics of heavy tailed and strongly correlated systems.


\paragraph{Norm-based capacity control theory.}

There is also a large body of work on using norm-based metrics to bound generalization error~\cite{NTS15, BFT17_TR, LMBx18_TR}.
In this area, theoretical work aims to prove generalization bounds, and applied work uses these norms as a regularization function to improve training.
While we do find that norms provide relatively good quality metrics, at least for distinguishing good-better-best among well-trained models, we are not interested in proving generalization bounds or improving training.


\paragraph{Practical problems poorly addressed by theory.}
There are many very practical problems in ML that are poorly addressed by existing theory and that either motivated our work or should be addressable by our techniques.
Here are several.
\begin{itemize}
\item
\textbf{Simplicity, or lack of,  accuracy metrics.}
\michael{XXX.  Put in two or at most three sentences.}
\item
\textbf{Information leakage in the production pipeline.}
\michael{XXX.  Put in two or at most three sentences.}
\item
\textbf{Cost of acquring labeled data.}
\michael{XXX.  Put in two or at most three sentences.}
\end{itemize}
Importantly, there are many examples in ML where (as a practical matter) there is no reliable notion of accuracy, e.g., when generating fake text or realiztic chatbots, developing self driving cars, or just clusterting user profiles.
\footnote{For example, current chatbots use perplexity as a proxy for passing a Turing test.}
%, and when distilling a reliable model in some way to obtain comparable training/test quality but that damages the model in some other subtle way. 
%\michael{That last example is awkward.  It would be good to have a better example and plant seeds for model distillation elsewhere.}
