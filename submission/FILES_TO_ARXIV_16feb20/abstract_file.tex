
In many practical applications, one works with deep neural network (DNN) models trained by someone else.
For such \emph{pretrained models}, one typically does not have access to training data or test data.
Moreover, one does not know many details about the model, such as the specifics of the training data, the loss function, the hyperparameter values, etc.
Given one or many pretrained models, can one say anything about the expected performance or quality of the models?
Here, we present and evaluate empirical quality metrics for pretrained DNN models at scale.
Using the open-source \emph{WeightWatcher} tool, we analyze hundreds of publicly-available pretrained models, including older and current state-of-the-art models in computer vision (CV) and natural language processing (NLP).
We examine both familiar norm-based capacity control metrics (Frobenius and Spectral norms) as well as newer Power Law (PL) based metrics (including fitted PL exponents, $\alpha$, and the Weighted Alpha metric, $\hat{\alpha}$), from the recently-developed Theory of Heavy-Tailed Self Regularization (HT-SR).
We also introduce the $\alpha$-Shatten Norm metric.
We find that norm-based metrics correlate well with reported test accuracies for well-trained models across nearly all CV architecture series.
On the other hand, we find that norm-based metrics can not distinguish ``good-versus-bad'' models---which, arguably is the point of needing quality metrics.  
Indeed, they may give spurious results.
We also find that PL-based metrics do much better---quantitatively better at discriminating among a series of ``good-better-best'' models, and qualitatively better at discriminating ``good-versus-bad'' models.
PL-based metrics can also be used to characterize fine-scale properties of these models, and we introduce the layer-wise \emph{Correlation Flow} as new quality assessment.
We show how poorly-trained (and/or poorly fine-tuned) models may exhibit both \emph{Scale Collapse} and unusually large PL exponents, $\alpha\gg 6$, in particular for recent NLP models.
Our techniques, as implemented in the \emph{WeightWatcher} tool, can be used to identify when a pretrained DNN has problems that can not be detected simply by examining training/test accuracies.


