\vspace{-1mm}
\section{Comparing Hundreds of CV Models}
\label{sxn:all_cv_models}

In this section, we summarize results from a large-scale analysis of hundreds of CV models, including models developed for image 
classification, segmentation, and a range of related tasks.  
Our aim is to complement the detailed results from Sections~\ref{sxn:cv} and~\ref{sxn:nlp} by providing broader conclusions. 
The models we consider have been pretrained on nine datasets.   
We provide full details about how to reproduce these results in Appendix~\ref{sxn:appendix}.

\begin{table}[t]
\small
\begin{center}
\begin{tabular}{|p{1in}|c|c|c|c|}
\hline
Series        & $\log\Vert\cdot\Vert_{F}$ & $\log\Vert\cdot\Vert_{\infty}$ & $\hat{\alpha}$ & $\log\Vert\cdot\Vert^{\alpha}_{\alpha}$ \\
\hline
$R^{2}$ (mean) & 0.63 &  0.55 & \textbf{0.64} & \textbf{0.64} \\
$R^{2}$ (std)  & 0.34 &  0.36 & \textbf{0.29} &          0.30 \\
\hline
$MSE$ (mean)   & 4.54 &  9.62 &          3.14 & \textbf{2.92} \\
$MSE$ (std)    & 8.69 & 23.06 &          5.14 & \textbf{5.00} \\
\hline
\end{tabular}
\end{center}
\caption{Comparison of linear regression fits for different average Log Norm and Weighted Alpha metrics across 5 CV datasets, 17 architectures, covering 108 (out of over 400) different pretrained DNNs.  
         We include regressions only for architectures with five or more data points, and which are positively correlated with test error.
         These results can be readily reproduced using the Google Colab notebooks (see Appendix~\ref{sxn:appendix}). 
        }
\label{table:results}
\end{table}


We choose ordinary least squares (OLS) regression to quantify the relationship between quality metrics (computed with the \emph{WeightWatcher} tool) 
and the reported test error and/or accuracy metrics.
We regress the metrics on the Top1 (and Top5) reported errors (as dependent variables).
These include Top5 errors for the ImageNet-1K model, percent error for the CIFAR-10/100, SVHN, CUB-200-2011 models, and Pixel accuracy
(Pix.Acc.) and Intersection-Over-Union (IOU) for other models.
We regress them individually on each of the norm-based and PL-based metrics, as described in Section~\ref{sxn:cv}.

Our results are summarized in Table~\ref{table:results}.
For the mean, larger $R^{2}$ and smaller $MSE$ are desirable; and for the standard deviation, smaller values are desirable.
Taken as a whole, over the entire corpus of data, PL-based metrics are somewhat better for both the $R^{2}$ mean and standard deviation;
and PL-based metrics are much better for $MSE$ mean and standard deviation.
These (and other) results suggest our conclusions from Sections~\ref{sxn:cv} and~\ref{sxn:nlp} hold much more generally, and they suggest
obvious questions for future work.

