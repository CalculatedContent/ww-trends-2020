%KDD% 
\vspace{-1mm}
\section{Comparing Hundreds of Models}
\label{sxn:all_cv_models}
%\vspace{-1mm}

In this section, we summarize results from a large-scale analysis of hundreds of publicly-available  models, including models developed for image 
classification, segmentation, and a range of related tasks.  
Our aim is to provide a broad analysis that complements the detailed analysis in Sections~\ref{sxn:cv} and~\ref{sxn:nlp}.
There, we considered CV and NLP models with similar structures. 
Here, we provide much broader conclusions based on a much larger set of models with a much more diverse set of structures. % about norm-based and PL-based metrics.
The models we consider have been pretrained on nine datasets.   %, shown in Table~\ref{table:datasets}.
%including ImageNet-1K, and CIFAR-10, CIFAR-100, Street View House Numbers (SVHN), Caltech-UCSD Birds-200-2011 (CUB-200-2011), Pascal VOC2012, ADE20K, Cityscapes, and Common Objects in Context (COCO). 
%%The pretrained models and their accuracy metrics are summarized in the osmr github~\cite{charles-add-link}.
We provide full details about how to reproduce these results in Appendix~\ref{sxn:appendix}.

\begin{table}[t]
\small
\begin{center}
\begin{tabular}{|p{1in}|c|c|c|c|}
%KDD% \begin{tabular}{|p{0.75in}|c|c|c|c|}
\hline
%    & Frobenius Norm & Spectral Norm & Weighted Alpha & Alpha-Norm \\
%    & $\langle\log\Vert\mathbf{W}\Vert_{F}\rangle$ & $\langle\log\Vert\mathbf{W}\Vert_{\infty}\rangle$ & $\langle\hat{\alpha}=\alpha\log\lambda_{max}\rangle$ & $\langle\log\Vert\mathbf{X}\Vert^{\alpha}_{\alpha}\rangle$ \\
Series        & $\log\Vert\cdot\Vert_{F}$ & $\log\Vert\cdot\Vert_{\infty}$ & $\hat{\alpha}$ & $\log\Vert\cdot\Vert^{\alpha}_{\alpha}$ \\
\hline
$R^{2}$ (mean) & 0.63 &  0.55 & \textbf{0.64} & \textbf{0.64} \\
$R^{2}$ (std)  & 0.34 &  0.36 & \textbf{0.29} &          0.30 \\
\hline
$MSE$ (mean)   & 4.54 &  9.62 &          3.14 & \textbf{2.92} \\
$MSE$ (std)    & 8.69 & 23.06 &          5.14 & \textbf{5.00} \\
\hline
\end{tabular}
\end{center}
\caption{Comparison of linear regression fits for different average Log Norm and Weighted Alpha metrics across 5 CV datasets, 17 architectures, covering 108 (out of over 400) different pretrained DNNs.  
         We include regressions only for architectures with five or more data points, and which are positively correlated with test error.
         These results can be readily reproduced using the Google Colab notebooks (see Appendix~\ref{sxn:appendix}). 
        }
\label{table:results}
\end{table}


We choose ordinary least squares (OLS) regression to quantify the relationship between quality metrics (computed with the \emph{WeightWatcher} tool) 
and the reported test error and/or accuracy metrics.
We regress the metrics on the Top1 (and Top5) reported errors (as dependent variables).
These include Top5 errors for the ImageNet-1K model, percent error for the CIFAR-10/100, SVHN, CUB-200-2011 models, and Pixel accuracy
(Pix.Acc.) and Intersection-Over-Union (IOU) for other models.
We regress them individually on each of the norm-based and PL-based metrics, as described in Section~\ref{sxn:cv}.

Our results are summarized in Table~\ref{table:results}.
For the mean, larger $R^{2}$ and smaller $MSE$ are desirable; and for the standard deviation, smaller values are desirable.
Taken as a whole, over the entire corpus of data, PL-based metrics are somewhat better for both the $R^{2}$ mean and standard deviation;
and PL-based metrics are much better for $MSE$ mean and standard deviation.
These (and other) results suggest our conclusions from Sections~\ref{sxn:cv} and~\ref{sxn:nlp} hold much more generally, and they suggest
obvious questions for future work.

