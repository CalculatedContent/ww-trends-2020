%\section{Reproducibility Appendix}
\section{Supplementary Information}
\label{sxn:appendix}


%%\subsection{Supplementary Tables} 
\subsection{Supplementary Details} 

\paragraph{Reproducing Sections \ref{sxn:cv} and \ref{sxn:nlp}. }   

We provide a github repository for this paper that includes Jupyter notebooks that fully reproduce all results (as well as many other results)~\cite{kdd20_sub_repo}.
All results have been produced using the \texttt{WeightWatcher} tool (v0.2.7)~\cite{weightwatcher_package}.
The ImageNet and OpenAI GPT pretrained models are provided in the current 
pyTorch~\cite{pytorch} and Huggingface~\cite{huggingface} distributions, as specified in the \texttt{requirements.txt}~file. 

\begin{table}[t]
\small
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Table & Figure & Jupyter Notebook \\
\hline
1 & \ref{fig:vgg-metrics}                                 & WeightWatcher-VGG.ipynb \\
1 & \ref{fig:resnet-accuracy}                             & WeightWatcher-ResNet.ipynb \\
1 & \ref{fig:resnet1k-accuracy}                           & WeightWatcher-ResNet-1K.ipynb \\
1 & \ref{fig:vgg-alpha-layers}                            & WeightWatcher-VGG.ipynb \\
1 & \ref{fig:resnet-alpha-layer}                          & WeightWatcher-ResNet.ipynb \\
1 & \ref{fig:densenet-alpha-layer}                        & WeightWatcher-DenseNet.ipynb \\
\hline
& \ref{fig:resnet204D5L}                                & WeightWatcher-Intel-Distiller-ResNet20.ipynb \\
\hline
2 & \ref{fig:GPT-hist}                                    & WeightWatcher-OpenAI-GPT.ipynb \\
2 & \ref{fig:gpt-alpha-layers}, \ref{fig:gpt2-histograms} & WeightWatcher-OpenAI-GPT2.ipynb \\
\hline
3,7,8,9 & Appendix & OSMR-Analysis.ipynb \\
\hline
\end{tabular}
\end{center}
\caption{Jupyter notebooks used to reproduce all results in Sections~\ref{sxn:cv} and~\ref{sxn:nlp}.\charles{Need to update referendes}}
\label{table:notebooks}
\end{table}


\paragraph{Reproducing Figure~\ref{fig:resnet204D5L}, for the Distiller Model.}

In the \texttt{distiller} folder of our github repo, 
we provide the original Jupyter Notebooks, which use the Intel \texttt{distiller} framework~\cite{distiller}.   % \footnote{\url{https://nervanasystems.github.io/distiller}} 
Figure~\ref{fig:resnet204D5L} is from the  \texttt{``...-Distiller-ResNet20.ipynb''} notebook (see Table~\ref{table:notebooks}).  
For completeness, we provide both the results described here, as well as additional results on other pretrained and distilled models using the \texttt{WeightWatcher} tool.


\paragraph{Reproducing Table~\ref{table:results} in Section~\ref{sxn:all_cv_models}. }

In the \texttt{ww-colab} folder of our github repo, we provide several Google Colab notebooks which can be used to reproduce the results of Section~\ref{sxn:all_cv_models}.
The ImageNet-1K and other pretrained models are taken from the pyTorch models in the \texttt{omsr/imgclsmob} 
``Sandbox for training convolutional networks for computer vision'' github repository~\cite{osmr}.
The data for each regression can be generated in parallel by running each Google Colab notebook (i.e., \texttt{ww\_colab\_0\_100.ipynb}) simultaneously on the same account.
The data generated are analyzed with \texttt{ww\_colab\_results.ipynb}, which runs all regressions and which tabulates the results presented in Table~\ref{table:results}.

We attempt to run linear regressions for all pyTorch models for each architecture series for all datasets provided.  
There are over $450$ models in all, and we note that the \texttt{osmr/imgclsmob} repository is constantly being updated with new models.
We omit the results for CUB-200-2011, Pascal-VOC2012, ADE20K, and COCO datasets, as there are fewer than 15 models for those datasets.  
Also, we filter out regressions with fewer than 5 datapoints.

We remove the following outliers, as identified by visual inspection: \texttt{efficient\_b0,\_b2}.
We also remove the entire \texttt{cifar100} \texttt{ResNeXT} series, which is the only example to show no trends with the norm metrics.
%
%The final datasets used are shown in Table~\ref{table:datasets}.
The final architecture series used are shown in  Table~\ref{table:architectures}, with the number of models in each.

Tables and figures summarizing this analysis (in a more fine-grained way than provided by Table~\ref{table:results}) are presented next.


%%\begin{figure}[t]
%%    \centering
%%    \subfigure[ImageNet 1K]{
%%        \includegraphics[width=4.9cm]{img/all-imagenet-1k_alpha.png}
%%        \label{fig:imagenet1k-alpha}
%%    }
%%    \qquad
%%    \subfigure[ CIFAR 10 ]{
%%        \includegraphics[width=4.9cm]{img/all-cifar-10_alpha.png}
%%        \label{fig:cifar10.alpha}
%%    }
%%    \qquad
%%    \subfigure[ CIFAR 100 ]{
%%        \includegraphics[width=4.9cm]{img/all-cifar-100_alpha.png}
%%        \label{fig:cifar100.alpha}
%%    }
%%    \qquad
%%    \subfigure[ SVHN ]{
%%        \includegraphics[width=4.9cm]{img/all-svhn_alpha.png}
%%        \label{fig:svhn.alpha}
%%    }
%%    \qquad
%%    \subfigure[ CUB 200 ]{
%%        \includegraphics[width=4.9cm]{img/all-cub-200-2011_alpha.png}
%%        \label{fig:cub200.alpha}
%%    }
%%    \caption{PL exponent $\alpha$ versus reported Top1 Test Accuracies for pretrained DNNs available for different datasets (as segmented in Table~\ref{table:datasets}).
%%            }
%%    \label{fig:DSalphas}
%%\end{figure}
%%
%% 
%%\begin{figure}[t]
%%    \centering
%%    \subfigure[ ResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_01}
%%    }
%%    \subfigure[ SENet/SE-ResNet/SE-PreResNet/SE-ResNeXt ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_02}
%%    }
%%    \subfigure[ DIA-ResNet/DIA-PreResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_03}
%%    }
%%    \subfigure[ ResNeXt ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_04}
%%    }
%%    \subfigure[ WRN ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_05}
%%    }
%%    \subfigure[ DLA ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_06}
%%    }
%%    \subfigure[ PreResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_07}
%%    }
%%    \subfigure[ ProxylessNAS ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_08}
%%    }
%%    \subfigure[ VGG/BN-VGG ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_09}
%%    }
%%    \subfigure[ IGCV3 ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_10}
%%    }
%%    \subfigure[ EfficientNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_11}
%%    }
%%    \subfigure[ SqueezeNext/SqNxt ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_12}
%%    }
%%    \subfigure[ ShuffleNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_13}
%%    }
%%    \subfigure[ DRN-C/DRN-D ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_14}
%%    }
%%    \subfigure[ ESPNetv2 ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_15}
%%    }
%%    \subfigure[ HRNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_16}
%%    }
%%    \subfigure[ SqueezeNet/SqueezeResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_17}
%%    }
%%    \caption{PL exponent $\alpha$ versus reported Top1 Test Accuracies for pretrained DNNs available for different architecture series (as segmented in Table~\ref{table:architectures}).
%%            }
%%    \label{fig:ARCHalphas}
%%\end{figure}


\input{table_6}

\input{table_RMSE}
\input{table_R2}
\input{table_Ktau}


%%\subsection{Supplementary Figures}
\subsection{Supplementary Tables and Figures}

\michael{Charles, would you put in a couple of paragraphs about how you generated the tables/figures in the appendix, and a few things we learn from them, i.e., basically enough to convince that reviewer that we paid attention to their concerns.}

\michael{Table~\ref{table:architectures} still needs to be fixed, since it does not include the overall results partitioned by dataset that we had in the old Table~\ref{table:datasets}. }

To explain further how to reproduce our analysis, we run three batches of linear regressions. 
First, at the global level, we divide models by datasets and run regressions separately on all models of a certain dataset, regardless of the architecture. 
At this level, the plots are quite noisy and clustered, as each architecture has its own accuracy trend; but one can
 still see that most plots show positive relationship with positive coefficients. 
% V1 REMOVED FOR V2 % Example regressions are shown in Figure~\ref{fig:DSalphas}, as available in the results notebook.
%%Example regressions are shown in 
%%Figure~\ref{fig:DSalphas}, for models segmented by dataset, as listed in Table~\ref{table:datasets}, 
%%and in 
%%Figure~\ref{fig:ARCHalphas}, for models segmented by architecture, as listed in Table~\ref{table:architectures}.
\michael{Charles, this paragraph is stale since it refers to the old figures that the reviewer did not like, so would you update it.}

To generate the results in Table~\ref{table:results}, we run linear regressions for each architecture series in Table~\ref{table:architectures}, regressing each empirical Log Norm metric against the reported Top1 (and Top5) errors (as listed on the \texttt{osmr/imgclsmob} github repository README file~\cite{osmr}, with the relevant data extracted and provided in our github repo as \texttt{pytorchcv.html}).
We record the $RMSE$, $R^{2}$, and Kendall-$\tau$ for each metric, averaged over all regressions for all architectures and datasets;
see Table~\ref{table:RMSEresults}, Table~\ref{table:R2results}, and Table~\ref{table:Ktauresults}, respectively.
\michael{Charles, the label is broken in the caption of Table~\ref{table:RMSEresults}, Table~\ref{table:R2results}, and Table~\ref{table:Ktauresults}.}
In the repo, plots are provided for every regression, and more fine grained results may be computed by the reader by analyzing the data in the \texttt{df\_all.xlsx} file.
The final analysis includes 108 regressions in all, those with 4 or more models, with a positive $R^2$.

See
Figure~\ref{fig:summary_regressions_A},
Figure~\ref{fig:summary_regressions_B},
Figure~\ref{fig:summary_regressions_C},
Figure~\ref{fig:summary_regressions_D},
Figure~\ref{fig:summary_regressions_E},
Figure~\ref{fig:summary_regressions_F},
Figure~\ref{fig:summary_regressions_G},
Figure~\ref{fig:summary_regressions_H}, and
Figure~\ref{fig:summary_regressions_I} for more details.
\michael{Charles, would you put a bit of discussion, e.g., on best and worst, again just a teaser to satisfy that reviewer.}


\input{figs_largeScale_A}
\input{figs_largeScale_B}
\input{figs_largeScale_C}
\input{figs_largeScale_D}
\input{figs_largeScale_E}
\input{figs_largeScale_F}
\input{figs_largeScale_G}
\input{figs_largeScale_H}
\input{figs_largeScale_I}



\subsection{Supplementary Discussion: Additional Details on HT-SR Theory}

The original work on HT-SR Theory~\cite{MM18_TR,MM19_HTSR_ICML,MM20_SDM} considered NNs including AlexNet and InceptionV3 (as well as DenseNet, ResNet, and VGG), and it showed that for nearly every $\mathbf{W}$, the (bulk and tail) of the ESDs can be fit to a truncated PL and the PL exponents $\alpha$ nearly all lie within the range $\alpha\in(1.5,5)$.
Our meta-analysis, the main results of which are summarized in this paper, has shown that these results are ubiquitous.
For example, 
upon examining nearly 10,000 layer weight matrices $\mathbf{W}_{l,i}$ across hundreds of different modern pre-trained DNN architectures, the ESD of nearly every $\mathbf{W}$ layer matrix can be fit to a truncated PL:
$70-80\%$ of the time, the fitted PL exponent $\alpha$ lies in the range $\alpha\in(2,4)$; and  
$10-20\%$ of the time, the fitted PL exponent $\alpha$ lies in the range $\alpha< 2$.  
Of course, there are exceptions: in any real DNN, the fitted $\alpha$ may range anywhere from $\sim 1.5$ to $10$ or higher (and, of course, larger values of $\alpha$ may indicate that the PL is not a good model for the data).  
Still, overall, in nearly all large, pre-trained DNNs, the correlations in the  weight matrices exhibit a remarkable Universality, being both Heavy Tailed, and having small---but not too small---PL exponents. 

