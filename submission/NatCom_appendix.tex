>%\section{Reproducibility Appendix}
\section{Supplementary Information}
\label{sxn:appendix}


%%\subsection{Supplementary Tables} 
\subsection{Supplementary Details} 

\paragraph{Reproducing Sections \ref{sxn:cv} and \ref{sxn:nlp}. }   

We provide a github repository for this paper that includes Jupyter notebooks that fully reproduce all results (as well as many other results)~\cite{kdd20_sub_repo}.
All results have been produced using the \texttt{WeightWatcher} tool)~\cite{weightwatcher_package}.
The ImageNet and OpenAI GPT pretrained models are provided in the current 
pyTorch~\cite{pytorch} and Huggingface~\cite{huggingface} distributions.

\begin{table}[t]
\small
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Table & Figure & Jupyter Notebook \\
\hline
1 & \ref{fig:vgg-metrics}                                 & WeightWatcher-VGG.ipynb \\
1 & \ref{fig:resnet-accuracy}                             & WeightWatcher-ResNet.ipynb \\
1 & \ref{fig:resnet1k-accuracy}                           & WeightWatcher-ResNet-1K.ipynb \\
1 & \ref{fig:vgg-alpha-layers}                            & WeightWatcher-VGG.ipynb \\
1 & \ref{fig:resnet-alpha-layer}                          & WeightWatcher-ResNet.ipynb \\
1 & \ref{fig:densenet-alpha-layer}                        & WeightWatcher-DenseNet.ipynb \\
\hline
& \ref{fig:resnet204D5L}                                & WeightWatcher-Intel-Distiller-ResNet20.ipynb \\
\hline
2 & \ref{fig:GPT-hist}                                    & WeightWatcher-OpenAI-GPT.ipynb \\
2 & \ref{fig:gpt-alpha-layers}, \ref{fig:gpt2-histograms} & WeightWatcher-OpenAI-GPT2.ipynb \\
\hline
3,7,8,9 & Appendix & OSMR-Analysis.ipynb \\
\hline
\end{tabular}
\end{center}
\caption{Jupyter notebooks used to reproduce all results in Sections~\ref{sxn:cv} and~\ref{sxn:nlp}.\charles{Need to update referendes}}
\label{table:notebooks}
\end{table}


\paragraph{Reproducing Figure~\ref{fig:resnet204D5L}, for the Distiller Model.}

In the \texttt{distiller} folder of our github repo, 
we provide the original Jupyter Notebooks, which use the Intel \texttt{distiller} framework~\cite{distiller}.   % \footnote{\url{https://nervanasystems.github.io/distiller}} 
Figure~\ref{fig:resnet204D5L} is from the  \texttt{``...-Distiller-ResNet20.ipynb''} notebook (see Table~\ref{table:notebooks}).  
For completeness, we provide both the results described here, as well as additional results on other pretrained and distilled models using the \texttt{WeightWatcher} tool.


\paragraph{Reproducing Table~\ref{table:results} in Section~\ref{sxn:all_cv_models}. }

The reader may regenerate all of the  results of Section~\ref{sxn:all_cv_models} 
\texttt{WeightWatcher} results using the Google Colab Jupyter notebooks (in the \texttt{ww-colab} folder)
and  the \texttt{WeightWatcher} tool, 
and/or simply reproduce 
Table~\ref{table:results}, as well as Tables~\ref{table:RMSEresults}-\ref{table:Ktauresults}
and  Figures~\ref{fig:summary_regressions_A}-\ref{fig:summary_regressions_I},
using the Jupyter notebooks (shown in Table~\ref{table:notebooks}),
and the pre-computed \texttt{WeightWatcher} datasets (in the \texttt{data/osmr} folder).
The pretrained models, trained on ImageNet-1K and the other datasets, 
are taken from the pyTorch models in the \texttt{omsr/imgclsmob} 
``Sandbox for training convolutional networks for computer vision'' github repository~\cite{osmr}.
The full  \texttt{WeightWatcher} results are provided in the datasets: \texttt{[data/osmr/data...xlsx]},
last generated in January 2020, using the Google Colab notebooks: \texttt{[ww\_colab/ww\_colab...ipynb]},
and \texttt{WeightWatcher} version ww0.2.7.  Results can be recomputed using the current version (ww0.4.1)
using the \texttt{ww2x=True} back compatability option, although note the pretrained models must
be downloaded and  may have changed slightly.
The data files currently provided are analyzed with the \texttt{OSMR-Analysis.ipynb} python Juyter Notebook,
which runs all regressions and which tabulates the results presented in 
Table~\ref{table:results}
and generates the figures in Figures~\ref{fig:summary_regressions_A}-\ref{fig:summary_regressions_I}
and Tables

We attempt to run linear regressions for all pyTorch models for each architecture series for all datasets provided.  
There are over $450$ models in all to consider, and we note that the \texttt{osmr/imgclsmob} repository is constantly being updated with new models.
We omit the results for CUB-200-2011, Pascal-VOC2012, ADE20K, and COCO datasets, as there are fewer than 15 models for those datasets.  
Also, we filter out regressions with fewer than 5 datapoints.

We remove the following outliers, as identified by visual inspection: \texttt{efficient\_b0,\_b2}.
We also remove the entire \texttt{cifar100} \texttt{ResNeXT} series, which is the only example to show no trends with the norm metrics.
%
%The final datasets used are shown in Table~\ref{table:datasets}.
The final architecture series used are shown in  Table~\ref{table:architectures}, with the number of models in each.

Tables and figures summarizing this analysis (in a more fine-grained way than provided by Table~\ref{table:results}) are presented next.


%%\begin{figure}[t]
%%    \centering
%%    \subfigure[ImageNet 1K]{
%%        \includegraphics[width=4.9cm]{img/all-imagenet-1k_alpha.png}
%%        \label{fig:imagenet1k-alpha}
%%    }
%%    \qquad
%%    \subfigure[ CIFAR 10 ]{
%%        \includegraphics[width=4.9cm]{img/all-cifar-10_alpha.png}
%%        \label{fig:cifar10.alpha}
%%    }
%%    \qquad
%%    \subfigure[ CIFAR 100 ]{
%%        \includegraphics[width=4.9cm]{img/all-cifar-100_alpha.png}
%%        \label{fig:cifar100.alpha}
%%    }
%%    \qquad
%%    \subfigure[ SVHN ]{
%%        \includegraphics[width=4.9cm]{img/all-svhn_alpha.png}
%%        \label{fig:svhn.alpha}
%%    }
%%    \qquad
%%    \subfigure[ CUB 200 ]{
%%        \includegraphics[width=4.9cm]{img/all-cub-200-2011_alpha.png}
%%        \label{fig:cub200.alpha}
%%    }
%%    \caption{PL exponent $\alpha$ versus reported Top1 Test Accuracies for pretrained DNNs available for different datasets (as segmented in Table~\ref{table:datasets}).
%%            }
%%    \label{fig:DSalphas}
%%\end{figure}
%%
%% 
%%\begin{figure}[t]
%%    \centering
%%    \subfigure[ ResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_01}
%%    }
%%    \subfigure[ SENet/SE-ResNet/SE-PreResNet/SE-ResNeXt ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_02}
%%    }
%%    \subfigure[ DIA-ResNet/DIA-PreResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_03}
%%    }
%%    \subfigure[ ResNeXt ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_04}
%%    }
%%    \subfigure[ WRN ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_05}
%%    }
%%    \subfigure[ DLA ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_06}
%%    }
%%    \subfigure[ PreResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_07}
%%    }
%%    \subfigure[ ProxylessNAS ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_08}
%%    }
%%    \subfigure[ VGG/BN-VGG ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_09}
%%    }
%%    \subfigure[ IGCV3 ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_10}
%%    }
%%    \subfigure[ EfficientNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_11}
%%    }
%%    \subfigure[ SqueezeNext/SqNxt ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_12}
%%    }
%%    \subfigure[ ShuffleNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_13}
%%    }
%%    \subfigure[ DRN-C/DRN-D ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_14}
%%    }
%%    \subfigure[ ESPNetv2 ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_15}
%%    }
%%    \subfigure[ HRNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_16}
%%    }
%%    \subfigure[ SqueezeNet/SqueezeResNet ]{
%%        \includegraphics[width=2.7cm]{img/hex.png}
%%        \label{fig:ARCHalphas_17}
%%    }
%%    \caption{PL exponent $\alpha$ versus reported Top1 Test Accuracies for pretrained DNNs available for different architecture series (as segmented in Table~\ref{table:architectures}).
%%            }
%%    \label{fig:ARCHalphas}
%%\end{figure}


\input{table_6}

\input{table_RMSE}
\input{table_R2}
\input{table_Ktau}


%%\subsection{Supplementary Figures}
\subsection{Supplementary Tables and Figures}

\michael{Charles, would you put in a couple of paragraphs about how you generated the tables/figures in the appendix, and a few things we learn from them, i.e., basically enough to convince that reviewer that we paid attention to their concerns.}
\charles{fixed below}
\michael{Table~\ref{table:architectures} still needs to be fixed, since it does not include the overall results partitioned by dataset that we had in the old Table~\ref{table:datasets}. }

%To explain further how to reproduce our analysis, we run three batches of linear regressions. 
%First, at the global level, we divide models by datasets and run regressions separately on all models of a certain dataset, regardless of the architecture. 
%At this level, the plots are quite noisy and clustered, as each architecture has its own accuracy trend; but one can
% still see that most plots show positive relationship with positive coefficients. 
% V1 REMOVED FOR V2 % Example regressions are shown in Figure~\ref{fig:DSalphas}, as available in the results notebook.
%%Example regressions are shown in 
%%Figure~\ref{fig:DSalphas}, for models segmented by dataset, as listed in Table~\ref{table:datasets}, 
%%and in 
%%Figure~\ref{fig:ARCHalphas}, for models segmented by architecture, as listed in Table~\ref{table:architectures}.
%\michael{Charles, this paragraph is stale since it refers to the old figures that the reviewer did not like, so would you update it.}

Table~\ref{table:results} and Figures~\ref{fig:summary_regressions_A}-\ref{fig:summary_regressions_I} below present results for OLS 
(Ordinary Least Squares) regressions for every dataset and architecture series listed in Table~\ref{table:architectures},
 created by running the \texttt{WeightWatcher} tool (version 0.2.7)~\cite{weightwatcher_package}
on numerous pretrained models taken from the \texttt{OSMR/imgclsmob Sandbox} github repository of pretrained CV DNN model
ggithub repository. \michael{citation here ?}
In each Figure,  each row of subfigures, for a given pretrained model and dataset, depicts the average Norm-based and Power Law metrics
 ($\langle\log\Vert\cdot\Vert_{F}\rangle$,    $\langle\log\Vert\cdot\Vert_{\infty}\rangle$,
$\hat{\alpha}$,  $\langle\log\Vert\cdot\Vert^{\alpha}_{\alpha}\rangle$)
 against the Top1 Test Accuracy, as reported in the github repository README file~\cite{osmr} ),
along with a shaded area representing the $95\%$ confidence bound.
For each regression, we report the RMSE, R2 regresssion metrics, and Kendal-$\tau$ rank correlation metric,
both in the title of each subfiguire, and in Table~\ref{table:RMSEresults}, Table~\ref{table:R2results}, and Table~\ref{table:Ktauresults}, respectively.
To reproduce these Figures and Tables, see the \texttt{OSMR-Analysis.ipynb} python Jupyter Notebook, as listed in Table~\ref{},
and provided github repo accompanying this paper.
The reader may regenerate these Figures and Tables,
and even more fine grained results, by rerunning
 the \texttt{OSMR-Analysis.ipynb} python Jupyter Notebook (see Table~\ref{table:notebooks}), which 
analyzes the precomputed data in the \texttt{df\_all.xlsx} file. 
This repository also contains the original \texttt{Google Colab} notebooks, run in January 2020, 
which downloads the pretrained models and  and runs the \texttt{WeightWatcher} tool on them.
%To generate the results in Table~\ref{table:results}, we run linear regressions for each architecture series in Table~\ref{table:architectures}, regressing each empirical Log Norm metric against the reported Top1 rrors (as listed on the \texttt{osmr/imgclsmob} github repository README file~\cite{osmr}, with the relevant data extracted and provided in our github repo as \texttt{pytorchcv.html}).
%We record the $RMSE$, $R^{2}$, and Kendall-$\tau$ for each metric, averaged over all regressions for all architectures and datasets;
%see Table~\ref{table:RMSEresults}, Table~\ref{table:R2results}, and Table~\ref{table:Ktauresults}, respectively.
%captions fixed in table Ktau.  
%In the repo, plots are provided for every regression, and more fine grained results may be computed by the reader by analyzing the data in the \texttt{df\_all.xlsx} file.
The reader may also run the  \texttt{WeightWatcher} locally on each of the 
pretrained models,
such as the ResNet models, trained on the ImageNet-1K dataset, using the \texttt{WeightWatcher-ResNet-1K.ipynb} notebook.
(However, note that the models may have changed, giving slightly different results).
The final analysis includes 108 regressions in all.%, those with 4 or more models.%, with a positive $R^2$.
See Figure~\ref{fig:summary_regressions_A}-\ref{fig:summary_regressions_I} for more details.
%5Figure~\ref{fig:summary_regressions_B},
%Figure~\ref{fig:summary_regressions_C},
%Figure~\ref{fig:summary_regressions_D},
%Figure~\ref{fig:summary_regressions_E},
%Figure~\ref{fig:summary_regressions_F},
%Figure~\ref{fig:summary_regressions_G},
%Figure~\ref{fig:summary_regressions_H}, and

\michael{Charles, would you put a bit of discussion, e.g., on best and worst, again just a teaser to satisfy that reviewer.}
\charles{below}
From these Figures, we recognize fits of varying quality, ranging from remarkably good to completely uncorrelated.
Starting with the best, consider the Imagenet-1K PreResNet results.  Figure~\ref{fig:summary_regressions_A_10} shows 
the Avg. Log Spectral Norm $\langle\log\Vert\mathbf{W}\Vert^{2}_{\infty}\rangle$, 
which has a rather large $RMSE=3.93$, and rather small $R2=0.36$, and Kendal-$\tau=0.54$, and
has 6 out of 13 points outside the $95\%$ confidence bands.  In contrast, 
the Avg. Log Alpha Norm $\langle\log\Vert\mathbf{W}\Vert^{\alpha}_{\alpha}\rangle$, 
in  Figure~\ref{fig:summary_regressions_A_12} , 
has a much smaller $RMSE=1.93$, and much larger  $R2=0.85$, and Kendal-$\tau=0.87$, 
and only 2 points outside the $95\%$ confidence bands.
For examples of lower quality fits, consider the SqueezeNext results, as shown Figures~\ref{fig:summary_regressions_C_10} and 
~\ref{fig:summary_regressions_C_12}.  
The Avg. Log Spectral Norm $\langle\log\Vert\mathbf{W}\Vert^{2}_{\infty}\rangle$ appears
visually anti-correlated with the test accuracies
(as it is with ShuffleNet, in Figure ~\ref{fig:summary_regressions_B_02}).
It has a very large $95\%$ confidence band, with only 2 points close to the regression line, 
a large RMSE,  $R2=0.07$ (i.e zero), and small Kendal-$\tau=0.33$.  
The Avg. Log Alpha Norm $\langle\log\Vert\mathbf{W}\Vert^{\alpha}_{\alpha}\rangle$ is (as always) positively-correlated
with test accuracies, but with $R2=0.43$, show some linear correaltion, and a reasonable Kendal-$\tau=0.73$,
showing moderately strong rank correlation.

\input{figs_largeScale_A}
\input{figs_largeScale_B}
\input{figs_largeScale_C}
\input{figs_largeScale_D}
\input{figs_largeScale_E}
\input{figs_largeScale_F}
\input{figs_largeScale_G}
\input{figs_largeScale_H}
\input{figs_largeScale_I}



\subsection{Supplementary Discussion: Additional Details on HT-SR Theory}

The original work on HT-SR Theory~\cite{MM18_TR,MM19_HTSR_ICML,MM20_SDM} considered DNNs including AlexNet and InceptionV3 (as well as DenseNet, ResNet, and VGG), and it showed that for nearly every $\mathbf{W}$, the (bulk and tail) of the ESDs can be fit to a truncated PL and the PL exponents $\alpha$ nearly all lie within the range $\alpha\in(1.5,5)$.
Our meta-analysis, the main results of which are summarized in this paper, has shown that these results are ubiquitous.
For example, 
upon examining nearly 10,000 layer weight matrices $\mathbf{W}_{l,i}$ across hundreds of different modern pre-trained DNN architectures, the ESD of nearly every $\mathbf{W}$ layer matrix can be fit to a truncated PL:
$70-80\%$ of the time, the fitted PL exponent $\alpha$ lies in the range $\alpha\in(2,4)$; and  
$10-20\%$ of the time, the fitted PL exponent $\alpha$ lies in the range $\alpha< 2$.  
Of course, there are exceptions: in any real DNN, the fitted $\alpha$ may range anywhere from $\sim 1.5$ to $10$ or higher (and, of course, larger values of $\alpha$ may indicate that the PL is not a good model for the data).  
Still, overall, in nearly all large, pre-trained DNNs, the correlations in the  weight matrices exhibit a remarkable Universality, being both Heavy Tailed, and having small---but not too small---PL exponents. 

