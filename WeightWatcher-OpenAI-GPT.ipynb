{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface OpenAI GPT and GPT2 models\n",
    "\n",
    "Hugginface comes with several versions of the OpenAI GPT model for generating facke test\n",
    "\n",
    "Here, we compare the original GPT with the later GPT2. \n",
    "\n",
    "Both models have the exact same architecture, but arev trained with different size data sets.\n",
    "The GPT2 model is trained with a much larger data set and performs significantly better:\n",
    "\n",
    "\n",
    "_\"GPT-2 is a direct scale-up of GPT, with more than 10X the parameters and trained on more than 10X the amount of data.\"_  \n",
    "\n",
    " https://openai.com/blog/better-language-models/\n",
    "\n",
    "\n",
    "### Observations\n",
    "\n",
    "- The distrobution of $\\alpha$ exponents is smaller\n",
    "- Information flow is better in GPT2\n",
    "- Frobenius and Spectral Norms are Larger for GPT2 vs GPT\n",
    "- Embedding / first 2 layers, and last couple layes, have unusually large spectral norms\n",
    "\n",
    "#### Could be a normalization issue ?\n",
    "\n",
    "- BUT I think we see rank collapse in GPT, throwing the metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import random, datetime\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import os, gc, logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import weightwatcher as ww\n",
    "print(\"weightwatcher version {}\".format(ww.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import OpenAIGPTModel,GPT2Model\n",
    "print(\"transformers version {}\".format(transformers.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = OpenAIGPTModel.from_pretrained('openai-gpt')\n",
    "gpt_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model = GPT2Model.from_pretrained('gpt2')\n",
    "gpt2_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watcher = ww.WeightWatcher(model=gpt_model, logger=logger)\n",
    "results = watcher.analyze(alphas=True, softranks=True, spectralnorms=True, plot=False)\n",
    "\n",
    "summary =  watcher.get_summary()\n",
    "\n",
    "details  = watcher.get_details(results=results)\n",
    "details.drop(columns=['slice', 'slice_count'], inplace=True)\n",
    "details.dropna(inplace=True)\n",
    "details['NxM'] = pd.to_numeric(details.N * details.M) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watcher = ww.WeightWatcher(model=gpt2_model, logger=logger)\n",
    "results2 = watcher.analyze(alphas=True, softranks=True, spectralnorms=True, plot=True)\n",
    "\n",
    "summary2 =  watcher.get_summary()\n",
    "\n",
    "details2  = watcher.get_details(results=results2)\n",
    "details2.drop(columns=['slice', 'slice_count'], inplace=True)\n",
    "details2.dropna(inplace=True)\n",
    "details2['NxM'] = pd.to_numeric(details2.N * details2.M) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [(x) for x in details['alpha'].to_numpy()]\n",
    "alpha2 = [(x) for x in details2['alpha'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsnorm = [np.log10(x) for x in details['spectralnorm'].to_numpy()]\n",
    "logsnorm2 = [np.log10(x) for x in details2['spectralnorm'].to_numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (10, 7),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(alpha, bins=100, color='blue', alpha=0.5, density=True, label='openAI GPT')\n",
    "plt.hist(alpha2, bins=100, color='red', alpha=0.5, density=True, label='openAI GPT2')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Histogram: Power Law exponents $(\\alpha)$ \")#for layers of\"+\"\\nOpenAI GPT and GPT2 Pretrained Models\")\n",
    "plt.xlabel(r\"Power Law exponent $(\\alpha)$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"img/GPT-alpha-hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(logsnorm, bins=100, color='blue', alpha=0.5, density=True, label='openAI GPT')\n",
    "plt.hist(logsnorm2, bins=100, color='red', alpha=0.5, density=True, label='openAI GPT2')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Histogram: Spectral Norms $(\\log\\Vert\\mathbf{W}\\Vert_{\\infty})$\" )\n",
    "          #for layers of\"+\"\\nOpenAI GPT and GPT2 Pretrained Models\")\n",
    "plt.xlabel(r\"log Spectral Norm $(\\log\\Vert\\mathbf{W}\\Vert_{\\infty})$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"img/GPT-snorm-hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(details.index)\n",
    "y = details.alpha.to_numpy(dtype=np.float)\n",
    "plt.scatter(x,y, label='GPT')\n",
    "\n",
    "y2 = details2.alpha.to_numpy(dtype=np.float)\n",
    "plt.scatter(x,y2, label='GPT2')\n",
    "\n",
    "plt.xlabel(\"layer id \")\n",
    "plt.ylabel(r\"$\\alpha$\")\n",
    "plt.legend()\n",
    "plt.title(r\"PL Exponent in GPT and GPT2\"+ \"\\n\"+r\"$\\alpha$ vs layer id\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/GPT-alpha-depth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details.alpha[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(details.index)\n",
    "y = np.log10(details.spectralnorm.to_numpy(dtype=np.float))\n",
    "plt.scatter(x,y, label='GPT')\n",
    "\n",
    "y2 = np.log10(details2.spectralnorm.to_numpy(dtype=np.float))\n",
    "plt.scatter(x,y2, label='GPT2')\n",
    "\n",
    "plt.xlabel(\"layer id \")\n",
    "plt.ylabel(r\"$\\log\\Vert\\mathbf{W}\\Vert_{\\infty}$\")\n",
    "plt.legend()\n",
    "plt.title(\"Log Spectral Norms in GPT and GPT2\\n\"+r\"$\\log\\;\\Vert\\mathbf{W}\\Vert_{\\infty}$ vs layer id\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"img/GPT-snorm-depth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(details.index)\n",
    "y = details.logpnorm.to_numpy(dtype=np.float)\n",
    "plt.scatter(x,y, label='GPT')\n",
    "\n",
    "y2 = details2.logpnorm.to_numpy(dtype=np.float)\n",
    "plt.scatter(x,y2, label='GPT2')\n",
    "\n",
    "plt.xlabel(\"layer id \")\n",
    "plt.ylabel(r\"$\\log\\Vert\\mathbf{X}\\Vert_{\\alpha}^{\\alpha}$\")\n",
    "plt.legend()\n",
    "plt.title(r\"Log $\\alpha$-Norms in GPT and GPT2\"+\"\\n\"+r\"$\\log\\;\\Vert\\mathbf{X}\\Vert_{\\alpha}^{\\alpha}$ vs layer id\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"img/GPT-pnorm-depth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = summary\n",
    "\" & {:.2f} & {:.2f} & {:.2f} & {:.2f} \\\\\".format(s['lognorm'], s['spectralnorm'], s['alpha_weighted'], s['logpnorm'] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avglogmetric(d, col):\n",
    "    norm = d[col].to_numpy(dtype=np.float)\n",
    "    lognorm=np.log10(norm)\n",
    "    avglognorm = np.average(lognorm)\n",
    "    return avglognorm\n",
    "\n",
    "def avgmetric(d, col):\n",
    "    norm = d[col].to_numpy(dtype=np.float)\n",
    "    avgnorm = np.average(norm)\n",
    "    return avgnorm\n",
    "\n",
    "for s, d in zip([summary, summary2],[details, details2]):\n",
    "    \n",
    "    d = d[d.level==ww.LEVEL.SLICE]\n",
    "    d = d.loc[2:]\n",
    "\n",
    "    avglognorm = avglogmetric(d, 'norm')\n",
    "    avglogsnorm = avglogmetric(d, 'spectralnorm')\n",
    "    avgwalpha = avgmetric(d, 'alpha_weighted')\n",
    "    avglogpnorm = avgmetric(d, 'logpnorm')\n",
    "    \n",
    "    line = \" & {} & {:.2f} &{:.2f}& {:.2f} & {:.2f} \\\\\\\\\"\n",
    "    print(line.format(len(d),avglognorm,avglogsnorm,avgwalpha,avglogpnorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
